{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# fastai 0.7.2, kinda worked - downloaded into a folder. But then dunno how to import and use it properly...\n#!pip install -e git+https://github.com/fastai/fastai1@e85667cfae2e6873b1bb026195b5d09a74dfcff9#egg=fastai07\n#%load_ext autoreload\n#%autoreload 2\n#%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install fastai==0.7.0 --no-deps\n!pip install scikit-learn==0.21.3\n# fastai depends also on an older version of torch\n!pip install torch==0.4.1 torchvision==0.2.1\n!pip show fastai","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install treeinterpreter\n!pip install waterfallcharts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.imports import *\nfrom fastai.structured import *\n\nfrom pandas_summary import DataFrameSummary\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom IPython.display import display\n\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\ndf = pd.read_csv('/kaggle/input/heroes-of-the-storm-matches-sample/export_flat_form.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_vals(a,n): \n    return a[:n].copy(), a[n:].copy()\n\ndef rmse(x,y):\n    return math.sqrt(((x-y)**2).mean())\n\ndef print_score(m):\n    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing\nCheck info on the events, i.e. date range, plot date distribution to get a clearer view about the data, then drop the date column entirely since it is useless information for our models."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.date = pd.to_datetime(df[\"date\"])\ndates_ordinal = pd.Series([x.toordinal() for x in df.date])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First check the dates and filter the ones that would be too old for us to be usable."},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot non-parametric kde on numeric datenum\nax = dates_ordinal.plot(kind='kde')\n# rename the xticks with labels\nx_ticks = ax.get_xticks()\nax.set_xticks(x_ticks[::2])\nxlabels = [datetime.datetime.fromordinal(int(x)).strftime('%Y-%m-%d') for x in x_ticks[::2]]\nax.set_xticklabels(xlabels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's keep just last 5 months dates"},{"metadata":{"trusted":true},"cell_type":"code","source":"#see if there are any missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates_mask = (df.date > '2020-10-01')\ndf_newer_dates = df.loc[dates_mask]\ndates_ordinal_newer = pd.Series([x.toordinal() for x in df_newer_dates.date])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot non-parametric kde on numeric datenum\nax = dates_ordinal_newer.plot(kind='kde')\n# rename the xticks with labels\nx_ticks = ax.get_xticks()\nax.set_xticks(x_ticks[::2])\nxlabels = [datetime.datetime.fromordinal(int(x)).strftime('%Y-%m-%d') for x in x_ticks[::2]]\nax.set_xticklabels(xlabels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_date = df.date.min()\nmax_date = df.date.max()\nprint(\"older match: \"+ str(min_date)+\"   newest match: \"+str(max_date))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_date = df_newer_dates.date.min()\nmax_date = df_newer_dates.date.max()\nprint(\"older match: \"+ str(min_date)+\"   newest match: \"+str(max_date))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_size = 30000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw = df_newer_dates.drop(columns=['date'])\nprint(df_raw.shape)\ndf_raw = df_raw.sample(n = sample_size, random_state = 1, axis = 0)\nprint(df_raw.shape)\ndf_raw.reset_index(drop=True, inplace=True)\n#print(df_raw.tail())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"invert_ratio = 0.5\nn_inv = int(len(df_raw) * invert_ratio)\ndf_standard, df_inverted = split_vals(df_raw, n_inv)\n#print(df_inverted.head())\ndf_inverted = df_inverted.rename(columns={\"winnerA\": \"loserA\", \"winnerB\": \"loserB\", \"winnerC\": \"loserC\", \"winnerD\": \"loserD\", \"winnerE\": \"loserE\",\n                            \"loserA\": \"winnerA\", \"loserB\": \"winnerB\", \"loserC\": \"winnerC\", \"loserD\": \"winnerD\", \"loserE\": \"winnerE\"})\n#df.loc[idx] = df.loc[idx].rename(columns={'R':'L','L':'R'})\ndf_inverted['outcome'] = 0\ndf_mixed = df_standard.append(df_inverted)\n#print(df_mixed.head())\n#print(df_mixed.tail())\ndf_mixed.outcome.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cats(df_mixed)\nprint([len(df_mixed[x].cat.categories) for x in df.columns[1:13]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### if it throws error here, it means tables were cleared, need to re-run from the import of csv:"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nhero_names = df_mixed['winnerA'].cat.categories\nheroes_total = max(hero_names)\nmap_names = df_mixed['game_map'].cat.categories\n\nprint([len(df_mixed[x].cat.categories) for x in df.columns[1:13]], \"  heroes_total =\", heroes_total)\nprint(hero_names[:9], \"...\")\n#df_mixed.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#clear up memory:\ndates_ordinal_newer = 0\ndates_ordinal = 0\ndf = pd.DataFrame()\ndf_raw = pd.DataFrame()\ndf_standard = pd.DataFrame()\ndf_inverted = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great, shuffling worked. Another problem is the format of the table itself. We are more interested in relations between features more than anything else, therefore let's transform the table into something mode understandable for the Tree type model. For that, the first idea to try - split the features into \"multiple-hot\" encoding table. Not sure if this is even a thing, but let's try that. A one-hot encoder would give us a great start, so let's use that."},{"metadata":{"trusted":true},"cell_type":"code","source":"winner_cols = ['winnerA', 'winnerB', 'winnerC', 'winnerD', 'winnerE']\nloser_cols = ['loserA', 'loserB', 'loserC', 'loserD', 'loserE']\ndummies_data = pd.DataFrame(columns = hero_names, dtype = 'int8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def hero_hot_transform(game_map = '', game_type = 'UnrankedDraft', winners = [], losers = [], bans = []):\n    new_row = pd.Series(index = hero_names, dtype = 'int8')\n    for x in hero_names:\n        if x in winners:\n            new_row[x] = 2\n        if x in losers:\n            new_row[x] = 1\n    game_map_index = df_mixed['game_map'].cat.categories.get_loc(game_map) \n    game_type_index = df_mixed['game_type'].cat.categories.get_loc(game_type)        \n\n    #print(dict( enumerate(df_mixed['game_map'].cat.categories ) ))\n    new_row = new_row.append(pd.Series([game_map_index, game_type_index], index = ['game_map','game_type']))\n    return new_row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"game_map = 'Garden of Terror'\ngame_type = 'UnrankedDraft'\nwinners=['Auriel', 'Muradin']\nlosers=['Illidian', 'Abathur']\nrow = [hero_hot_transform(game_map = game_map, game_type=game_type, winners = winners, losers=losers)]\nrow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index in range(0, int(len(df_mixed))): #\n    game_map = df_mixed['game_map'].iloc[index]\n    game_type = df_mixed['game_type'].iloc[index]\n\n    winners = list(df_mixed[winner_cols].iloc[index].astype(str))\n    losers = list(df_mixed[loser_cols].iloc[index].astype(str))\n    #bans =\n    dummies_data = dummies_data.append(hero_hot_transform(game_map = game_map, game_type=game_type, winners = winners, losers = losers), ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummies_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('total mem: ', sum(dummies_data.memory_usage()) / 1000)\nprint(dummies_data.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummies_data = pd.concat([dummies_data, df_mixed[['outcome']]], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummies_data.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare train and val sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"#need this again for new dataframe, cause we attached strings when transforming\n#train_cats(dummies_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_trn, y_trn, nas = proc_df(dummies_data, 'outcome')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_required_ratio = 0.8\nn_trn = int(len(df_trn) * train_required_ratio)\nX_train, X_valid = split_vals(df_trn, n_trn)\ny_train, y_valid = split_vals(y_trn, n_trn)\nX_train.shape, X_valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"apply_cats(X_valid, X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Start with simple and stupid"},{"metadata":{"trusted":true},"cell_type":"code","source":"m = RandomForestRegressor(n_estimators=1, max_depth=3, bootstrap=False, n_jobs=-1)\n%time m.fit(X_train, y_train)\nprint_score(m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_tree(m.estimators_[0], df_trn, size = 20, precision=3)\n#?draw_tree","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Try Out Bagging ?\ndont remember what is it.. gotta read about it more"},{"metadata":{"trusted":true},"cell_type":"code","source":"#preds = np.stack([t.predict(X_valid) for t in m.estimators_])\n#preds[:,0], np.mean(preds[:,0]), y_valid[0]\n#preds.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.plot([metrics.r2_score(y_valid, np.mean(preds[:i+1], axis=0)) for i in range(10)]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Subsampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#set_rf_samples(2000) #if you set_rf_samples - cannot use OOB score, so dont put the parameter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#m = RandomForestRegressor(n_estimators=20, n_jobs=-1, oob_score=False)\n#%time m.fit(X_train, y_train)\n#print_score(m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reset_rf_samples()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#m = RandomForestRegressor(n_estimators=20, min_samples_leaf=3, n_jobs=-1, oob_score=False) #min_samples_leaf = 1-3-5-10-25 are good vals\n#%time m.fit(X_train, y_train)\n#print_score(m)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"things to try:\nmax_features = 0.5, 'sqrt', 'log2'\nleafs = 1, 3, 5, 10, 25, 50, 100..."},{"metadata":{"trusted":true},"cell_type":"code","source":"#m = RandomForestRegressor(n_estimators=20, min_samples_leaf=3, max_features = 0.2, n_jobs=-1, oob_score=True) #max_features = 1-0.5-0.2, sqrt are good vals\n#%time m.fit(X_train, y_train)\n#print_score(m)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well seems like max_features < 1 are not helping, also subsampling doesnt help either.  Let's get back to base mode, with more estimators."},{"metadata":{"trusted":true},"cell_type":"code","source":"m = RandomForestRegressor(n_estimators=100, n_jobs=-1)\n%time m.fit(X_train, y_train)\nprint_score(m)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Would feature importance show hero importance in case if I transformed the table to hero-based?"},{"metadata":{"trusted":true},"cell_type":"code","source":"fi = rf_feat_importance(m, df_trn); fi[:10]\ndef plot_fi(fi): return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\nplot_fi(fi[:50]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to_keep = fi[fi.imp>0.005].cols; len(to_keep)\n#df_keep = df_trn[to_keep].copy()\n#X_train, X_valid = split_vals(df_keep, n_trn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"checking how correlated the features are:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.cluster import hierarchy as hc\n\ncorr = np.round(scipy.stats.spearmanr(df_trn).correlation, 3)\ncorr_condensed = hc.distance.squareform(pow((1-corr), 3))\nz = hc.linkage(corr_condensed, method='complete')\nfig = plt.figure(figsize=(8,16))\ndendrogram = hc.dendrogram(z, labels=df_trn.columns, orientation='left', leaf_font_size=10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ggplot(df, aes())+stat_smooth() is a very powerfull graphics lib, coming from R\nuse get_sample(df, n) to decrease complexity of graph\nhttps://forums.fast.ai/t/unofficial-lesson-4-classnotes/7569\npdp - partial dependence plot library"},{"metadata":{},"cell_type":"markdown","source":"since the data is patch dependent, it would be better to weight recent matches more whent training. most modeling algorithms can be adjusted via some weight constant"},{"metadata":{},"cell_type":"raw","source":"Add tree interpreter to interpreter to show impact from each hero in the concrete setup #Lesson 5 - 48:00"},{"metadata":{"trusted":true},"cell_type":"code","source":"from treeinterpreter import treeinterpreter as ti\nrow = X_valid.values[None,0]; row\ndf_train, df_valid = split_vals(dummies_data, n_trn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test if tree is properly interpreted\n#prediction, bias, contributions = ti.predict(m, row)\n#idxs = np.argsort(contributions[0])\n#[(a, b, c) for (a, b, c) in zip(dummies_data.columns[idxs], df_valid.iloc[0][idxs], contributions[0][idxs])  if (a in ['game_map', 'game_type'] or b != 0)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Try interpret a custom data input:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def prognoses(model, game_map, game_type, winners, losers):\n    input_row = np.asarray([hero_hot_transform(game_map = game_map, game_type=game_type, winners = winners, losers=losers)])\n    prediction, bias, contributions_input = ti.predict(model, input_row)\n    idxs = np.argsort(contributions_input[0])\n    interpretations = [(a, b, c) for (a, b, c) in zip(dummies_data.columns[idxs], input_row[0][idxs], contributions_input[0][idxs])  if b != 0]\n    rest = [(a, b, c) for (a, b, c) in zip(dummies_data.columns[idxs], input_row[0][idxs], contributions_input[0][idxs])  if b == 0]\n\n    change = sum([c for c in contributions_input[0][idxs]])\n\n    outcome = bias[0] + change\n    #print(interpretations)\n    #print(bias, change, [c for (a, b, c) in interpretations])\n    if bias[0] + change > 0.5:\n        print(\"your team is expected to win (>0.5): \",outcome)\n    else:\n        print(\"your team is expected to lose (<0.5): \",outcome)\n    return (bias, interpretations, rest)\n#this is wrong, because I zip wrong things, so values are right, but titles are not","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make a function to draw two waterfalls side by side, one for each team\n#https://github.com/chrispaulca/waterfall/blob/master/Tree_interpreter_Example.ipynb\n#https://github.com/chrispaulca/waterfall\nimport waterfall_chart\n\ndef draw_interpretation_waterfalls(bias, interpretations, rest):\n    winner_team_interps = [(a, b, c) for (a, b, c) in interpretations if (a in hero_names and b == 2)]\n    loser_team_interps = [(a, b, c) for (a, b, c) in interpretations if (a in hero_names and b == 1)]\n\n    colnames_winner = [a for (a, b, c) in winner_team_interps]\n    colnames_loser = [a for (a, b, c) in loser_team_interps]\n    conts_winner = [c for (a, b, c) in winner_team_interps]\n    conts_loser = [c for (a, b, c) in loser_team_interps]\n    \n    colname_totals = ['bias','your team', 'opponents','map','type', 'rest']\n    map_interp = [c for (a, b, c) in interpretations if (a == 'game_map')]\n    type_interp = [c for (a, b, c) in interpretations if (a == 'game_type')]\n    rest_interp = [c for (a, b, c) in rest]\n    conts_totals = [bias[0],sum(conts_winner),sum(conts_loser), sum(map_interp), sum(type_interp), sum(rest_interp)]\n\n    winner_plot = waterfall_chart.plot(colnames_winner,conts_winner, rotation_value=90, threshold=0.0,formatting='{:,.4f}')\n    loser_plot = waterfall_chart.plot(colnames_loser,conts_loser, rotation_value=90, threshold=0.0,formatting='{:,.4f}')\n    totals_plot = waterfall_chart.plot(colname_totals,conts_totals, rotation_value=90, threshold=0.0,formatting='{:,.4f}')\n\n#conts = [contributions_input[0][i] for i in range(len(contributions_input[0]))]\n#colnames = dummies_data.columns[0:-1].values\n#my_plot = waterfall_chart.plot(colnames,conts, rotation_value=90, threshold=0.1,formatting='{:,.3f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"set inputs:"},{"metadata":{"trusted":true},"cell_type":"code","source":"map_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print hero names, to copy exactly:\nhero_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"game_map = 'Tomb of the Spider Queen'\ngame_type = 'UnrankedDraft'\nyour_team=['Brightwing', \"Kael'thas\", 'Leoric', \"Qhira\", 'Malthael']\nopponent_tea=['Johanna', 'Malfurion', 'Azmodan', 'Kerrigan', 'Blaze']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"calculate and draw out match prognosis:"},{"metadata":{"trusted":true},"cell_type":"code","source":"bias, prog, rest = prognoses(m, game_map, game_type, your_team, opponent_tea)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_interpretation_waterfalls(bias, prog ,rest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_row = np.asarray([hero_hot_transform(game_map = game_map, game_type=game_type, winners = your_team, losers=opponent_tea)])\nprediction = m.predict(input_row)\nprint(prediction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBoost part"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost\nmy_model_2 = xgboost.XGBRegressor(random_state=0, learning_rate = 0.2, n_estimators = 200)\nxgb_weights = pd.Series(np.linspace(0.5, 1, sample_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time my_model_2.fit(X_train, y_train, sample_weight_eval_set = xgb_weights, verbose=False) # , early_stopping_rounds=5, eval_set=[(X_valid, y_valid)] # throws assersion error\nprint_score(m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"?pl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import matplotlib.pylab as pl\n#plt.rcParams[\"figure.figsize\"] = (10, 15)\n#xgboost.plot_importance(my_model_2, height=0.75, importance_type=\"gain\") #, max_num_features=20\n#pl.title(\"xgboost.plot_importance(model)\")\n#pl.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap\nexplainer = shap.TreeExplainer(my_model_2)\nshap_values = explainer.shap_values(df_trn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values, X_train, plot_type=\"bar\",max_display=X_train.shape[1]) #scrollable\n#shap.summary_plot(shap_values[:,5:6], X.iloc[:, 5:6])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values, df_trn,alpha=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"?shap.summary_plot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.initjs()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to visualize single prediction with XGBoost use: shap:  https://slundberg.github.io/shap/notebooks/Census%20income%20classification%20with%20XGBoost.html\n#shap.force_plot(explainer.expected_value, shap_values[0,:], X_train.iloc[0,:])\ninput_row = np.asarray([hero_hot_transform(game_map = game_map, game_type=game_type, winners = winners, losers=losers)])\nshap.force_plot(explainer.expected_value, shap_values[1000,:], X_train.iloc[0,:])\n#How to show the concrete game??? output changes when shap_values[] indexer is changed... but does it input new vals? How to omit zeroes?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"?shap.force_plot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.force_plot(explainer.expected_value, shap_values[:200,:], X_train.iloc[:200,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#this doesnt show anything usefull..\nshap.dependence_plot(\"Auriel\", shap_values[10000:], df_trn[10000:], display_features=X_train, x_jitter = 0.15, alpha = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"?shap.dependence_plot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}