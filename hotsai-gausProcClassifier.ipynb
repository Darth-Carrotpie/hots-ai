{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/transform_hot_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_random_masks(a, n1, n2):\n",
    "    msk = np.random.rand(len(a)) < (n1 + n2)\n",
    "    msk1 = ((np.random.rand(len(a)) < n1/(n1+n2)) & msk)\n",
    "    msk2 = (~msk1 & msk)\n",
    "    return ~msk, msk1, msk2\n",
    "\n",
    "def rmse(x,y):\n",
    "    return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m):\n",
    "    res = [\"rmse(trn):\",rmse(m.predict(X_train), y_train), \" rmse(val):\",rmse(m.predict(X_valid), y_valid),\n",
    "                \" scr(trn):\",m.score(X_train, y_train), \" scr(val):\",m.score(X_valid, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hero_one_hot(game_map = '', winners = [], losers = []):\n",
    "    new_row = pd.Series(index = col_names, dtype = 'boolean')\n",
    "    new_row[:] = False\n",
    "    for x in hero_names:\n",
    "        if x in winners:\n",
    "            new_row['yours_'+x] = True\n",
    "        if x in losers:\n",
    "            new_row['theirs_'+x] = True\n",
    "    new_row[game_map] = True\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare X and Y for train and val sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn, y_trn, nas = proc_df(dummies_data, 'outcome')\n",
    "val_ratio = 0.2\n",
    "tst_ratio = 0.1\n",
    "#y_trn=y_trn.astype('bool')\n",
    "#n_trn = int(len(df_trn) * train_required_ratio)\n",
    "tr_mask, val_mask, test_mask = split_random_masks(df_trn, val_ratio, tst_ratio)\n",
    "X_train = df_trn[tr_mask].copy()\n",
    "y_train = y_trn[tr_mask].copy()\n",
    "X_valid = df_trn[tr_mask].copy()\n",
    "y_valid = y_trn[tr_mask].copy()\n",
    "X_test = df_trn[tr_mask].copy()\n",
    "y_test = y_trn[tr_mask].copy()\n",
    "\n",
    "print(\"train: \",X_train.shape, \"  val:\",X_valid.shape, \" tst: \", X_test.shape)\n",
    "apply_cats(X_valid, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training binary logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = LogisticRegression(random_state=0).fit(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = 'Garden of Terror'\n",
    "game_type = 'UnrankedDraft'\n",
    "winners=['Auriel', 'Muradin']\n",
    "losers=['Illidian', 'Abathur']\n",
    "row = [hero_one_hot(game_map = game_map, winners = winners, losers=losers)]\n",
    "model.predict(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "C_param_range = [0.75,0.9,1,1.1,1.5,2]\n",
    "acc_table = pd.DataFrame(columns = ['C_parameter','Accuracy'])\n",
    "acc_table['C_parameter'] = C_param_range\n",
    "for i in C_param_range:\n",
    "    # Apply logistic regression model to training data\n",
    "    lr = LogisticRegression(solver = 'lbfgs', penalty = 'l2', C = i,random_state = 0)\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict using model\n",
    "    y_pred = lr.predict(X_test)\n",
    "    \n",
    "    # Saving accuracy score in table\n",
    "    acc_table.iloc[j,1] = accuracy_score(y_test,y_pred)\n",
    "    j += 1\n",
    "acc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "S_param_range = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "acc_table = pd.DataFrame(columns = ['C_parameter','Accuracy', 'Time'])\n",
    "acc_table['C_parameter'] = S_param_range\n",
    "result = %timeit -n1 -r1 -o\n",
    "for i in S_param_range:\n",
    "\n",
    "    # Apply logistic regression model to training data\n",
    "    lr = LogisticRegression(solver = i, penalty = 'l2', C = 1,random_state = 0) #pen:\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict using model\n",
    "    y_pred = lr.predict(X_test)\n",
    "    \n",
    "    # Saving accuracy score in table\n",
    "    acc_table.iloc[j,1] = accuracy_score(y_test,y_pred)\n",
    "    acc_table.iloc[j,2] = result\n",
    "    \n",
    "    j += 1\n",
    "print(result)\n",
    "acc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "P_param_range = ['l1', 'l2', 'elasticnet', 'none']\n",
    "acc_table = pd.DataFrame(columns = ['P_parameter','Accuracy'])\n",
    "acc_table['P_parameter'] = P_param_range\n",
    "for i in P_param_range:\n",
    "    # Apply logistic regression model to training data\n",
    "    lr = LogisticRegression(solver = 'saga', penalty = i, C = 1,random_state = 0, l1_ratio=0.5)\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict using model\n",
    "    y_pred = lr.predict(X_test)\n",
    "    \n",
    "    # Saving accuracy score in table\n",
    "    acc_table.iloc[j,1] = accuracy_score(y_test,y_pred)\n",
    "    j += 1\n",
    "acc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
