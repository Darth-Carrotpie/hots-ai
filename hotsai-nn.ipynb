{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "\n",
    "from fastai.metrics import *\n",
    "import torch.nn as nn\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/transform_hot_full.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_names = pd.read_csv(\"exports/game_map_cats.csv\",header=None, index_col=0, squeeze=True).to_dict()\n",
    "map_names = [n for x, n, in m_names.items()]\n",
    "map_names_swapped = dict([(value, key) for key, value in m_names.items()])\n",
    "\n",
    "h_names= pd.read_csv(\"exports/hero_name_cats.csv\",header=None, index_col=0, squeeze=True).to_dict()\n",
    "hero_names = [n for x, n, in h_names.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mns = [x[1] for x in list(enumerate(map_names))]\n",
    "yhns = ['yours_'+x[1] for x in list(enumerate(hero_names))]\n",
    "thns = ['theirs_'+x[1] for x in list(enumerate(hero_names))]\n",
    "col_names =mns+yhns+thns\n",
    "\n",
    "def hero_one_full(game_map = '', winners = [], losers = []):\n",
    "    new_row = pd.Series(index = col_names, dtype = 'boolean')\n",
    "    new_row[:] = False\n",
    "    for x in hero_names:\n",
    "        if x in winners:\n",
    "            new_row['yours_'+x] = True\n",
    "        if x in losers:\n",
    "            new_row['theirs_'+x] = True\n",
    "    new_row[game_map] = True\n",
    "    return new_row\n",
    "\n",
    "def hero_hot_mini(game_map = '', winners = [], losers = []):\n",
    "    new_row = pd.Series(index = hero_names, dtype = 'int8')\n",
    "    for x in hero_names:\n",
    "        if x in winners:\n",
    "            new_row[x] = 2\n",
    "        if x in losers:\n",
    "            new_row[x] = 1\n",
    "    game_map_index = int(map_names_swapped[game_map])\n",
    "    new_row = new_row.append(pd.Series(game_map_index, index = ['game_map'], dtype = 'int8'))\n",
    "    return new_row\n",
    "\n",
    "def hero_one_hot(game_map = '', winners = [], losers = []):\n",
    "    return hero_one_full(game_map = game_map, winners = winners, losers = losers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_random_masks(a, n1, n2):\n",
    "    msk = np.random.rand(len(a)) < (n1 + n2)\n",
    "    msk1 = ((np.random.rand(len(a)) < n1/(n1+n2)) & msk)\n",
    "    msk2 = (~msk1 & msk)\n",
    "    return ~msk, msk1, msk2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, title=None):\n",
    "    plt.imshow(img, cmap='gray');\n",
    "    if title is not None: plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(12,6), rows=2, titles=None):\n",
    "    f = plt.figure(figsize = figsize)\n",
    "    cols = len(ims)//rows\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None: sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?plt.imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (3509, 188)   val: (3509, 188)  tst:  (3509, 188)\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 5000\n",
    "data1 = df.sample(n = SAMPLE_SIZE, random_state = 1, axis = 0)\n",
    "df_trn, y_trn, nas = proc_df(data1, 'outcome')\n",
    "val_ratio = 0.2\n",
    "tst_ratio = 0.1\n",
    "#y_trn=y_trn.astype('bool')\n",
    "#n_trn = int(len(df_trn) * train_required_ratio)\n",
    "tr_mask, val_mask, test_mask = split_random_masks(df_trn, val_ratio, tst_ratio)\n",
    "x_train = df_trn[tr_mask].copy()\n",
    "y_train = y_trn[tr_mask].copy()\n",
    "x_valid = df_trn[tr_mask].copy()\n",
    "y_valid = y_trn[tr_mask].copy()\n",
    "x_test = df_trn[tr_mask].copy()\n",
    "y_test = y_trn[tr_mask].copy()\n",
    "\n",
    "print(\"train: \",x_train.shape, \"  val:\", x_valid.shape, \" tst: \", x_test.shape)\n",
    "apply_cats(x_valid, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3509, 188)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_imgs = np.reshape(x_valid, (-1,28,28)); x_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show(x_imgs[0,10:15,10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots(x_imgs[:8], titles=y_valid[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net for Logistic Regression in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so this error is due to a bad python version, in 3.7 async is now a keyword..., need 3.6 python version to run this old fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(1000, 200),\n",
    "    nn.LogSoftmax(),\n",
    "    nn.Linear(200, 10),\n",
    "    nn.LogSoftmax()\n",
    ").cuda()\n",
    "#this is a two layer neural net\n",
    "#.cuda tells to run on GPU, if didnt say that, would run on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mp = ImageClasifireData.from_arrays(path, (x, y), (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss() #negative low likelyhood loss = cross entropy. Either binary or categorical\n",
    "metrics=[accuracy]\n",
    "opt=optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "?ModelData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(net, md, epochs=1, crit=loss, opt=opt, metrics=metrics) #pythorch uses word criterion instead of loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(net, md.val_dl)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.argmax(axis=1)[:5] #argmax > figures out on this axis (for 10 in this case), return the index of the max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.argmax(1) #saving this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(preds == y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(x_imgs[:8], titles=preds[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#we have just built a logistic regression, it is not a deep neural net yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(dims): return nn.Parameter(torch.randn(dims)/dims[0]) # because there are many layers, so need to make sure that the mean inputs not gonna change, otherwise its gonna diverge infinitely or converge it the number is bigger (gradient explosion)\n",
    "#google: kaiming he initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1_w = get_weights(28*28, 10) # Layer 1 weights\n",
    "        self.l1_b = get_weights(10)   # Layer 1 bias\n",
    "    def forward(self, x): #in pytorch it has special meaning, it will get called when the layer gets calculated, its gonna get passed data form previous layer\n",
    "        x = x.view(x.size(0), -1) #view = reshape\n",
    "        x = torch.matmul(x, self.l1_w) +self.l1_b # Linear layer\n",
    "        x = torch.log(torch.exp(x)/(torch.exp(x).sum(dim=0))) #this is a softmax (because we want all probabiliteis of outcomes to sumup to 1), so it behaves so tthat it returns something that behaves as probabilities\n",
    "        return x\n",
    "#there is a lot of info on pytorch website on how to create tensors and modify stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define a * x, which are weights, then\n",
    "#+b is called bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = LogReg().cuda()\n",
    "opt=optim.Adam(net2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(net2, md, epochs=1, crit=loss, opt=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1:19:30"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
